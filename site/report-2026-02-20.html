<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Report 2026-02-20</title>
    <style>
*,
*::before,
*::after {
    margin: 0;
    padding: 0;
    box-sizing: border-box;
}

:root {
    --text: #353740;
    --text-secondary: #6e6e80;
    --bg: #ffffff;
    --bg-secondary: #f7f7f8;
    --border: #e5e5e6;
    --accent: #10a37f;
    --link: #10a37f;
}

body {
    font-family: 'Söhne', -apple-system, BlinkMacSystemFont, 'Helvetica Neue', sans-serif;
    color: var(--text);
    background: var(--bg);
    line-height: 1.8;
    font-size: 17px;
    -webkit-font-smoothing: antialiased;
}

.site-header {
    border-bottom: 1px solid var(--border);
    padding: 20px 0;
    margin-bottom: 48px;
}

.site-header .container {
    display: flex;
    align-items: center;
    justify-content: space-between;
}

.site-header a {
    text-decoration: none;
    color: var(--text);
}

.site-title {
    font-size: 18px;
    font-weight: 600;
    letter-spacing: -0.01em;
}

.site-nav a {
    color: var(--text-secondary);
    text-decoration: none;
    font-size: 15px;
}

.container {
    max-width: 680px;
    margin: 0 auto;
    padding: 0 24px;
}

/* Index page */
.index-hero {
    padding: 80px 0 48px;
}

.index-hero h1 {
    font-family: Georgia, 'Times New Roman', serif;
    font-size: 44px;
    font-weight: 400;
    line-height: 1.15;
    letter-spacing: -0.02em;
    margin-bottom: 16px;
}

.index-hero p {
    font-size: 19px;
    color: var(--text-secondary);
    line-height: 1.6;
}

.report-list {
    list-style: none;
    padding: 0;
}

.report-item {
    border-top: 1px solid var(--border);
    padding: 32px 0;
}

.report-item:last-child {
    border-bottom: 1px solid var(--border);
}

.report-date {
    font-size: 14px;
    color: var(--text-secondary);
    text-transform: uppercase;
    letter-spacing: 0.05em;
    margin-bottom: 8px;
}

.report-item h2 {
    font-family: Georgia, 'Times New Roman', serif;
    font-size: 26px;
    font-weight: 400;
    line-height: 1.3;
    letter-spacing: -0.01em;
    margin-bottom: 8px;
}

.report-item h2 a {
    color: var(--text);
    text-decoration: none;
}

.report-item h2 a:hover {
    color: var(--accent);
}

.report-excerpt {
    color: var(--text-secondary);
    font-size: 16px;
    line-height: 1.6;
}

/* Article page */
.article-header {
    padding: 80px 0 40px;
    text-align: center;
}

.article-date {
    font-size: 14px;
    color: var(--text-secondary);
    text-transform: uppercase;
    letter-spacing: 0.05em;
    margin-bottom: 16px;
}

.article-header h1 {
    font-family: Georgia, 'Times New Roman', serif;
    font-size: 40px;
    font-weight: 400;
    line-height: 1.2;
    letter-spacing: -0.02em;
}

.article-body {
    padding-bottom: 80px;
}

.article-body h2,
.article-body h3 {
    font-family: Georgia, 'Times New Roman', serif;
    font-weight: 400;
    letter-spacing: -0.01em;
    margin-top: 48px;
    margin-bottom: 16px;
}

.article-body h2 {
    font-size: 30px;
    line-height: 1.25;
}

.article-body h3 {
    font-size: 24px;
    line-height: 1.3;
}

.article-body p {
    margin-bottom: 24px;
}

.article-body a {
    color: var(--link);
    text-decoration: underline;
    text-underline-offset: 2px;
    text-decoration-thickness: 1px;
}

.article-body a:hover {
    text-decoration-thickness: 2px;
}

.article-body strong {
    font-weight: 600;
}

.article-body em {
    font-style: italic;
}

.article-body blockquote {
    border-left: 3px solid var(--border);
    padding-left: 20px;
    margin: 32px 0;
    color: var(--text-secondary);
    font-style: italic;
}

.article-body code {
    font-family: 'Söhne Mono', 'Menlo', monospace;
    font-size: 0.9em;
    background: var(--bg-secondary);
    padding: 2px 6px;
    border-radius: 4px;
}

.article-body ul,
.article-body ol {
    margin-bottom: 24px;
    padding-left: 24px;
}

.article-body li {
    margin-bottom: 8px;
}

.back-link {
    display: inline-block;
    color: var(--text-secondary);
    text-decoration: none;
    font-size: 15px;
    padding: 40px 0 0;
}

.back-link:hover {
    color: var(--accent);
}

footer {
    border-top: 1px solid var(--border);
    padding: 32px 0;
    margin-top: 48px;
    text-align: center;
    font-size: 14px;
    color: var(--text-secondary);
}
</style>
</head>
<body>
    <header class="site-header">
        <div class="container">
            <a href="index.html" class="site-title">Preprint Alert</a>
            <nav class="site-nav">
                <a href="index.html">Archive</a>
            </nav>
        </div>
    </header>
    
    <main class="container">
        <div class="article-header">
            <div class="article-date">February 20, 2026</div>
            <h1>Report 2026-02-20</h1>
        </div>
        <div class="article-body">
            <p>Here&rsquo;s my engaging article synthesizing today&rsquo;s most interesting papers on reasoning in NLP:</p>
<h1>The Hidden Logic: New Insights into How Language Models Think and Reason</h1>
<p>Today brings fascinating revelations about how large language models really work - and sometimes, it&rsquo;s not what we expected. From surprising findings about persuasion without theory of mind to the emergence of persistent &ldquo;lab signatures&rdquo; in model behavior, researchers are peeling back the layers of artificial intelligence to understand its true nature.</p>
<p>Perhaps most intriguingly, <a href="https://arxiv.org/abs/2602.17045">Large Language Models Persuade Without Planning Theory of Mind</a> challenges our assumptions about how AI systems influence human beliefs. While we might expect successful persuasion to require sophisticated modeling of others&rsquo; mental states, it turns out language models can be remarkably effective persuaders without explicitly reasoning about others&rsquo; thoughts and beliefs. They seem to rely more on rhetorical strategies than careful planning - a finding that raises interesting questions about both AI capabilities and human susceptibility to influence.</p>
<p>This insight connects to a broader theme emerging in today&rsquo;s research about how language models actually process information. <a href="https://arxiv.org/abs/2602.17598">The Cascade Equivalence Hypothesis</a> reveals that many speech language models aren&rsquo;t doing the sophisticated end-to-end processing we assumed, but rather operating as implicit speech-to-text pipelines. Similarly, <a href="https://arxiv.org/abs/2602.16813">One-step Language Modeling via Continuous Denoising</a> shows that the seemingly complex process of generating text can be dramatically simplified using continuous flows rather than discrete diffusion steps.</p>
<p>These findings suggest we may need to revise our understanding of AI reasoning. <a href="https://arxiv.org/abs/2602.17127">The Emergence of Lab-Driven Alignment Signatures</a> introduces a sophisticated psychometric framework showing that many model behaviors we attribute to individual AI systems are actually persistent patterns linked to their training origins - &ldquo;lab signatures&rdquo; that persist across model versions.</p>
<p>But this doesn&rsquo;t mean language models aren&rsquo;t capable of sophisticated behavior. <a href="https://arxiv.org/abs/2602.17022">ReIn: Conversational Error Recovery with Reasoning Inception</a> demonstrates how injecting reasoning patterns can help models recover from errors without modifying their core parameters. And <a href="https://arxiv.org/abs/2602.17431">Fine-Grained Uncertainty Quantification</a> shows how we can better understand when models are confident in their reasoning versus operating under uncertainty.</p>
<p>The implications are profound. As we deploy these systems more widely, understanding their true reasoning capabilities - both strengths and limitations - becomes crucial. <a href="https://arxiv.org/abs/2602.17546">Learning to Stay Safe</a> shows how we can maintain model safety during fine-tuning by adaptively adjusting safety constraints based on real-time risk assessment. Meanwhile, <a href="https://arxiv.org/abs/2602.17443">AIDG</a> reveals interesting asymmetries in how models handle information - they&rsquo;re notably better at protecting information than extracting it.</p>
<p>What emerges is a picture of AI systems that are simultaneously more simple and more complex than we imagined - capable of sophisticated outputs through sometimes surprisingly straightforward mechanisms, while harboring subtle biases and patterns that we&rsquo;re only beginning to understand. As we continue to deploy these systems, this deeper understanding of their true nature will be essential for both improving their capabilities and ensuring their safe and effective use.</p>
<p>The journey to understand artificial reasoning continues, and today&rsquo;s papers suggest we may need to revise some of our fundamental assumptions about how these systems think and operate. The reality, as often happens in science, is more nuanced and fascinating than our initial theories suggested.</p>
        </div>
        <a href="index.html" class="back-link">&larr; All reports</a>
    </main>
    <footer>
        <div class="container">Generated by Preprint Alert Agent</div>
    </footer>
</body>
</html>